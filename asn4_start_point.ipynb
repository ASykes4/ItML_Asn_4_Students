{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from geopy import distance\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Simple Neural Networks\n",
    "\n",
    "For this assigment you'll do a realistic task - predicting fraud from transaction data. \n",
    "### Some Things to Note\n",
    "\n",
    "<ul>\n",
    "<li> The dataset is imbalanced. See: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data for some ideas\n",
    "<li> The locations, time, dob all likely aren't super useful on their own, but can be made into something more useful without much code or trouble. Think about how it may be useful to represent them. The data doesn't have missing rows, so this is the main data prep portion. \n",
    "<li> With respect to the above, and the other data here, we have a lot of rows of data. That means that we can generally handle data that is reasonably wide...\n",
    "</ul>\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "Your final goal is to produce a function that can be called to classify a transaction:\n",
    "<ul>\n",
    "<li> Please submit two .ipynb files - one where you did your work, and another that can use your model to make predictions. \n",
    "<li> In that prediction file, please ensure:\n",
    "    <ul>\n",
    "    <li> You have a function where I can load a file, and the end result is a classificaiton matrix of your prediction accuracy. \n",
    "    <li> You load a trained model. There's no training here. \n",
    "    <li> Any data prep stuff that is needed for your data should be built in here. I'm going to run a test file that is the exact same setup as the training data.\n",
    "    <li> I should be able to open the prediction file, load the test data, and click RUN ALL and things should work. \n",
    "    <li> In addition to that, please include a short (~1-2 paragraph) description of what you did. Include anything that was innovative/different as well as a note on:\n",
    "        <ul>\n",
    "        <li> Any imbalanced data steps. \n",
    "        <li> Treatment of the location and time variables. What did you do to them?\n",
    "        <li> Model structure (layers/size)\n",
    "        <li> Any optimization steps included - regularization, dropouts, feature selection, etc...\n",
    "        </ul>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "### Grades\n",
    "\n",
    "The grade breakdown is as follows:\n",
    "\n",
    "<ul>\n",
    "<li> Code preduces predictions - 40\n",
    "<li> Accuracy - 30\n",
    "<li> Explaination - 20\n",
    "<li> Balance/variable transformations - 10\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data\n",
    "ef = pd.read_csv(\"https://jrssbcrsefilesnait.blob.core.windows.net/3950data1/fraudTrain.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num                            merchant  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
       "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
       "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
       "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
       "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
       "\n",
       "        category     amt      first     last gender  \\\n",
       "0       misc_net    4.97   Jennifer    Banks      F   \n",
       "1    grocery_pos  107.23  Stephanie     Gill      F   \n",
       "2  entertainment  220.11     Edward  Sanchez      M   \n",
       "3  gas_transport   45.00     Jeremy    White      M   \n",
       "4       misc_pos   41.96      Tyler   Garcia      M   \n",
       "\n",
       "                         street            city  ...      lat      long  \\\n",
       "0                561 Perry Cove  Moravian Falls  ...  36.0788  -81.1781   \n",
       "1  43039 Riley Greens Suite 393          Orient  ...  48.8878 -118.2105   \n",
       "2      594 White Dale Suite 530      Malad City  ...  42.1808 -112.2620   \n",
       "3   9443 Cynthia Court Apt. 038         Boulder  ...  46.2306 -112.1138   \n",
       "4              408 Bradley Rest        Doe Hill  ...  38.4207  -79.4629   \n",
       "\n",
       "   city_pop                                job         dob  \\\n",
       "0      3495          Psychologist, counselling  1988-03-09   \n",
       "1       149  Special educational needs teacher  1978-06-21   \n",
       "2      4154        Nature conservation officer  1962-01-19   \n",
       "3      1939                    Patent attorney  1967-01-12   \n",
       "4        99     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ef.copy()\n",
    "df.drop(columns={\"Unnamed: 0\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1296675</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>...</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1274791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>693</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352</td>\n",
       "      <td>481</td>\n",
       "      <td>2</td>\n",
       "      <td>983</td>\n",
       "      <td>894</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>494</td>\n",
       "      <td>968</td>\n",
       "      <td>1296675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2019-04-22 16:02:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fraud_Kilback LLC</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Smith</td>\n",
       "      <td>F</td>\n",
       "      <td>0069 Robin Brooks Apt. 695</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Film/video editor</td>\n",
       "      <td>1977-03-23</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4403</td>\n",
       "      <td>131659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26669</td>\n",
       "      <td>28794</td>\n",
       "      <td>709863</td>\n",
       "      <td>3123</td>\n",
       "      <td>5617</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9779</td>\n",
       "      <td>5636</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.171920e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.035104e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.853762e+01</td>\n",
       "      <td>-9.022634e+01</td>\n",
       "      <td>8.882444e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.349244e+09</td>\n",
       "      <td>3.853734e+01</td>\n",
       "      <td>-9.022646e+01</td>\n",
       "      <td>5.788652e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.308806e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.603160e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.075808e+00</td>\n",
       "      <td>1.375908e+01</td>\n",
       "      <td>3.019564e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.284128e+07</td>\n",
       "      <td>5.109788e+00</td>\n",
       "      <td>1.377109e+01</td>\n",
       "      <td>7.586269e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.041621e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.002710e+01</td>\n",
       "      <td>-1.656723e+02</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.325376e+09</td>\n",
       "      <td>1.902779e+01</td>\n",
       "      <td>-1.666712e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.800429e+14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.650000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.462050e+01</td>\n",
       "      <td>-9.679800e+01</td>\n",
       "      <td>7.430000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.338751e+09</td>\n",
       "      <td>3.473357e+01</td>\n",
       "      <td>-9.689728e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.521417e+15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.752000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.935430e+01</td>\n",
       "      <td>-8.747690e+01</td>\n",
       "      <td>2.456000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.349250e+09</td>\n",
       "      <td>3.936568e+01</td>\n",
       "      <td>-8.743839e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.642255e+15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.314000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.194040e+01</td>\n",
       "      <td>-8.015800e+01</td>\n",
       "      <td>2.032800e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.359385e+09</td>\n",
       "      <td>4.195716e+01</td>\n",
       "      <td>-8.023680e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.992346e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.894890e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.669330e+01</td>\n",
       "      <td>-6.795030e+01</td>\n",
       "      <td>2.906700e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.371817e+09</td>\n",
       "      <td>6.751027e+01</td>\n",
       "      <td>-6.695090e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       trans_date_trans_time        cc_num           merchant       category  \\\n",
       "count                1296675  1.296675e+06            1296675        1296675   \n",
       "unique               1274791           NaN                693             14   \n",
       "top      2019-04-22 16:02:01           NaN  fraud_Kilback LLC  gas_transport   \n",
       "freq                       4           NaN               4403         131659   \n",
       "mean                     NaN  4.171920e+17                NaN            NaN   \n",
       "std                      NaN  1.308806e+18                NaN            NaN   \n",
       "min                      NaN  6.041621e+10                NaN            NaN   \n",
       "25%                      NaN  1.800429e+14                NaN            NaN   \n",
       "50%                      NaN  3.521417e+15                NaN            NaN   \n",
       "75%                      NaN  4.642255e+15                NaN            NaN   \n",
       "max                      NaN  4.992346e+18                NaN            NaN   \n",
       "\n",
       "                 amt        first     last   gender  \\\n",
       "count   1.296675e+06      1296675  1296675  1296675   \n",
       "unique           NaN          352      481        2   \n",
       "top              NaN  Christopher    Smith        F   \n",
       "freq             NaN        26669    28794   709863   \n",
       "mean    7.035104e+01          NaN      NaN      NaN   \n",
       "std     1.603160e+02          NaN      NaN      NaN   \n",
       "min     1.000000e+00          NaN      NaN      NaN   \n",
       "25%     9.650000e+00          NaN      NaN      NaN   \n",
       "50%     4.752000e+01          NaN      NaN      NaN   \n",
       "75%     8.314000e+01          NaN      NaN      NaN   \n",
       "max     2.894890e+04          NaN      NaN      NaN   \n",
       "\n",
       "                            street        city  ...           lat  \\\n",
       "count                      1296675     1296675  ...  1.296675e+06   \n",
       "unique                         983         894  ...           NaN   \n",
       "top     0069 Robin Brooks Apt. 695  Birmingham  ...           NaN   \n",
       "freq                          3123        5617  ...           NaN   \n",
       "mean                           NaN         NaN  ...  3.853762e+01   \n",
       "std                            NaN         NaN  ...  5.075808e+00   \n",
       "min                            NaN         NaN  ...  2.002710e+01   \n",
       "25%                            NaN         NaN  ...  3.462050e+01   \n",
       "50%                            NaN         NaN  ...  3.935430e+01   \n",
       "75%                            NaN         NaN  ...  4.194040e+01   \n",
       "max                            NaN         NaN  ...  6.669330e+01   \n",
       "\n",
       "                long      city_pop                job         dob  \\\n",
       "count   1.296675e+06  1.296675e+06            1296675     1296675   \n",
       "unique           NaN           NaN                494         968   \n",
       "top              NaN           NaN  Film/video editor  1977-03-23   \n",
       "freq             NaN           NaN               9779        5636   \n",
       "mean   -9.022634e+01  8.882444e+04                NaN         NaN   \n",
       "std     1.375908e+01  3.019564e+05                NaN         NaN   \n",
       "min    -1.656723e+02  2.300000e+01                NaN         NaN   \n",
       "25%    -9.679800e+01  7.430000e+02                NaN         NaN   \n",
       "50%    -8.747690e+01  2.456000e+03                NaN         NaN   \n",
       "75%    -8.015800e+01  2.032800e+04                NaN         NaN   \n",
       "max    -6.795030e+01  2.906700e+06                NaN         NaN   \n",
       "\n",
       "                               trans_num     unix_time     merch_lat  \\\n",
       "count                            1296675  1.296675e+06  1.296675e+06   \n",
       "unique                           1296675           NaN           NaN   \n",
       "top     0b242abb623afc578575680df30655b9           NaN           NaN   \n",
       "freq                                   1           NaN           NaN   \n",
       "mean                                 NaN  1.349244e+09  3.853734e+01   \n",
       "std                                  NaN  1.284128e+07  5.109788e+00   \n",
       "min                                  NaN  1.325376e+09  1.902779e+01   \n",
       "25%                                  NaN  1.338751e+09  3.473357e+01   \n",
       "50%                                  NaN  1.349250e+09  3.936568e+01   \n",
       "75%                                  NaN  1.359385e+09  4.195716e+01   \n",
       "max                                  NaN  1.371817e+09  6.751027e+01   \n",
       "\n",
       "          merch_long      is_fraud  \n",
       "count   1.296675e+06  1.296675e+06  \n",
       "unique           NaN           NaN  \n",
       "top              NaN           NaN  \n",
       "freq             NaN           NaN  \n",
       "mean   -9.022646e+01  5.788652e-03  \n",
       "std     1.377109e+01  7.586269e-02  \n",
       "min    -1.666712e+02  0.000000e+00  \n",
       "25%    -9.689728e+01  0.000000e+00  \n",
       "50%    -8.743839e+01  0.000000e+00  \n",
       "75%    -8.023680e+01  0.000000e+00  \n",
       "max    -6.695090e+01  1.000000e+00  \n",
       "\n",
       "[11 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   trans_date_trans_time  1296675 non-null  object \n",
      " 1   cc_num                 1296675 non-null  int64  \n",
      " 2   merchant               1296675 non-null  object \n",
      " 3   category               1296675 non-null  object \n",
      " 4   amt                    1296675 non-null  float64\n",
      " 5   first                  1296675 non-null  object \n",
      " 6   last                   1296675 non-null  object \n",
      " 7   gender                 1296675 non-null  object \n",
      " 8   street                 1296675 non-null  object \n",
      " 9   city                   1296675 non-null  object \n",
      " 10  state                  1296675 non-null  object \n",
      " 11  zip                    1296675 non-null  int64  \n",
      " 12  lat                    1296675 non-null  float64\n",
      " 13  long                   1296675 non-null  float64\n",
      " 14  city_pop               1296675 non-null  int64  \n",
      " 15  job                    1296675 non-null  object \n",
      " 16  dob                    1296675 non-null  object \n",
      " 17  trans_num              1296675 non-null  object \n",
      " 18  unix_time              1296675 non-null  int64  \n",
      " 19  merch_lat              1296675 non-null  float64\n",
      " 20  merch_long             1296675 non-null  float64\n",
      " 21  is_fraud               1296675 non-null  int64  \n",
      "dtypes: float64(5), int64(5), object(12)\n",
      "memory usage: 217.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Lat/Lon\n",
    "\n",
    "We can utilize lat/lon of the home and merchant in a useful way?\n",
    "\n",
    "Note: I left the section headers in from when I did it. You can remove them if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>...</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>...</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>...</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num                            merchant  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
       "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
       "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
       "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
       "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
       "\n",
       "        category     amt      first     last gender  \\\n",
       "0       misc_net    4.97   Jennifer    Banks      F   \n",
       "1    grocery_pos  107.23  Stephanie     Gill      F   \n",
       "2  entertainment  220.11     Edward  Sanchez      M   \n",
       "3  gas_transport   45.00     Jeremy    White      M   \n",
       "4       misc_pos   41.96      Tyler   Garcia      M   \n",
       "\n",
       "                         street            city  ...      long  city_pop  \\\n",
       "0                561 Perry Cove  Moravian Falls  ...  -81.1781      3495   \n",
       "1  43039 Riley Greens Suite 393          Orient  ... -118.2105       149   \n",
       "2      594 White Dale Suite 530      Malad City  ... -112.2620      4154   \n",
       "3   9443 Cynthia Court Apt. 038         Boulder  ... -112.1138      1939   \n",
       "4              408 Bradley Rest        Doe Hill  ...  -79.4629        99   \n",
       "\n",
       "                                 job         dob  \\\n",
       "0          Psychologist, counselling  1988-03-09   \n",
       "1  Special educational needs teacher  1978-06-21   \n",
       "2        Nature conservation officer  1962-01-19   \n",
       "3                    Patent attorney  1967-01-12   \n",
       "4     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  distance  \n",
       "0         0  0.872830  \n",
       "1         0  0.272310  \n",
       "2         0  0.975845  \n",
       "3         0  0.919802  \n",
       "4         0  0.868505  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latlong = gpd.GeoDataFrame(df[['lat','long']], geometry=gpd.points_from_xy(df['lat'], df['long']))\n",
    "merchlatlong = gpd.GeoDataFrame(df[['merch_lat','merch_long']], geometry=gpd.points_from_xy(df['merch_lat'], df['merch_long']))\n",
    "df['distance'] = latlong['geometry'].distance(merchlatlong['geometry'],align=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Time\n",
    "\n",
    "Can we make date/time and the date of birth into something useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_date_trans_time'] = df['trans_date_trans_time'].apply(lambda x: dt.datetime.fromisoformat(str(x)))\n",
    "df['dob'] = df['dob'].apply(lambda x: dt.datetime.fromisoformat(str(x)))\n",
    "df['age'] = df['trans_date_trans_time'] - df['dob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>distance</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>...</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872830</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>...</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272310</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>...</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919802</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868505</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num                            merchant  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
       "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
       "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
       "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
       "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
       "\n",
       "        category     amt      first     last gender  \\\n",
       "0       misc_net    4.97   Jennifer    Banks      F   \n",
       "1    grocery_pos  107.23  Stephanie     Gill      F   \n",
       "2  entertainment  220.11     Edward  Sanchez      M   \n",
       "3  gas_transport   45.00     Jeremy    White      M   \n",
       "4       misc_pos   41.96      Tyler   Garcia      M   \n",
       "\n",
       "                         street            city  ... city_pop  \\\n",
       "0                561 Perry Cove  Moravian Falls  ...     3495   \n",
       "1  43039 Riley Greens Suite 393          Orient  ...      149   \n",
       "2      594 White Dale Suite 530      Malad City  ...     4154   \n",
       "3   9443 Cynthia Court Apt. 038         Boulder  ...     1939   \n",
       "4              408 Bradley Rest        Doe Hill  ...       99   \n",
       "\n",
       "                                 job        dob  \\\n",
       "0          Psychologist, counselling 1988-03-09   \n",
       "1  Special educational needs teacher 1978-06-21   \n",
       "2        Nature conservation officer 1962-01-19   \n",
       "3                    Patent attorney 1967-01-12   \n",
       "4     Dance movement psychotherapist 1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "  is_fraud  distance  age  \n",
       "0        0  0.872830   30  \n",
       "1        0  0.272310   40  \n",
       "2        0  0.975845   56  \n",
       "3        0  0.919802   52  \n",
       "4        0  0.868505   32  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'] = df['age'].apply(lambda x: x.days//365)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Target Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 1296675\n",
      "    Positive: 7506 (0.58% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(df['is_fraud'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>amt</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>...</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>category_kids_pets</th>\n",
       "      <th>category_misc_net</th>\n",
       "      <th>category_misc_pos</th>\n",
       "      <th>category_personal_care</th>\n",
       "      <th>category_shopping_net</th>\n",
       "      <th>category_shopping_pos</th>\n",
       "      <th>category_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>4.97</td>\n",
       "      <td>28654</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630423337322</td>\n",
       "      <td>107.23</td>\n",
       "      <td>99160</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38859492057661</td>\n",
       "      <td>220.11</td>\n",
       "      <td>83252</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>45.00</td>\n",
       "      <td>59632</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375534208663984</td>\n",
       "      <td>41.96</td>\n",
       "      <td>24433</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cc_num     amt    zip      lat      long  city_pop   unix_time  \\\n",
       "0  2703186189652095    4.97  28654  36.0788  -81.1781      3495  1325376018   \n",
       "1      630423337322  107.23  99160  48.8878 -118.2105       149  1325376044   \n",
       "2    38859492057661  220.11  83252  42.1808 -112.2620      4154  1325376051   \n",
       "3  3534093764340240   45.00  59632  46.2306 -112.1138      1939  1325376076   \n",
       "4   375534208663984   41.96  24433  38.4207  -79.4629        99  1325376186   \n",
       "\n",
       "   merch_lat  merch_long  is_fraud  ...  category_grocery_pos  \\\n",
       "0  36.011293  -82.048315         0  ...                     0   \n",
       "1  49.159047 -118.186462         0  ...                     1   \n",
       "2  43.150704 -112.154481         0  ...                     0   \n",
       "3  47.034331 -112.561071         0  ...                     0   \n",
       "4  38.674999  -78.632459         0  ...                     0   \n",
       "\n",
       "   category_health_fitness  category_home  category_kids_pets  \\\n",
       "0                        0              0                   0   \n",
       "1                        0              0                   0   \n",
       "2                        0              0                   0   \n",
       "3                        0              0                   0   \n",
       "4                        0              0                   0   \n",
       "\n",
       "   category_misc_net  category_misc_pos  category_personal_care  \\\n",
       "0                  1                  0                       0   \n",
       "1                  0                  0                       0   \n",
       "2                  0                  0                       0   \n",
       "3                  0                  0                       0   \n",
       "4                  0                  1                       0   \n",
       "\n",
       "   category_shopping_net  category_shopping_pos  category_travel  \n",
       "0                      0                      0                0  \n",
       "1                      0                      0                0  \n",
       "2                      0                      0                0  \n",
       "3                      0                      0                0  \n",
       "4                      0                      0                0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop('trans_date_trans_time')\n",
    "df.pop('dob')\n",
    "df.pop('job')\n",
    "df.pop('trans_num')\n",
    "df.pop('merchant')\n",
    "df.pop('first')\n",
    "df.pop('last')\n",
    "df.pop('gender')\n",
    "df.pop('street')\n",
    "df.pop('city')\n",
    "df.pop('state')\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (829872,)\n",
      "Validation labels shape: (207468,)\n",
      "Test labels shape: (259335,)\n",
      "Training features shape: (829872, 24)\n",
      "Validation features shape: (207468, 24)\n",
      "Test features shape: (259335, 24)\n"
     ]
    }
   ],
   "source": [
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('is_fraud'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('is_fraud'))\n",
    "test_labels = np.array(test_df.pop('is_fraud'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)\n",
    "\n",
    "scale = StandardScaler()\n",
    "train_features = scale.fit_transform(train_features)\n",
    "val_features = scale.fit_transform(val_features)\n",
    "test_features = scale.fit_transform(test_features)\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(72, activation='relu',input_shape=(train_features.shape[-1],)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(36, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation='sigmoid',bias_initializer=output_bias)\n",
    "  ])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 72)                1800      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 72)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 36)                2628      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 36)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 37        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,465\n",
      "Trainable params: 4,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "model = make_model(metrics=METRICS)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 1.01\n",
      "Weight for class 1: 101.62\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 1.0)\n",
    "weight_for_1 = (1 / pos) * (total / 1.7)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "406/406 [==============================] - 4s 6ms/step - loss: 0.1211 - tp: 356.0000 - fp: 43734.0000 - tn: 781347.0000 - fn: 4435.0000 - accuracy: 0.9420 - precision: 0.0081 - recall: 0.0743 - auc: 0.7127 - prc: 0.0122 - val_loss: 0.0244 - val_tp: 79.0000 - val_fp: 81.0000 - val_tn: 206192.0000 - val_fn: 1116.0000 - val_accuracy: 0.9942 - val_precision: 0.4938 - val_recall: 0.0661 - val_auc: 0.8450 - val_prc: 0.2702\n",
      "Epoch 2/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0254 - tp: 571.0000 - fp: 529.0000 - tn: 824552.0000 - fn: 4220.0000 - accuracy: 0.9943 - precision: 0.5191 - recall: 0.1192 - auc: 0.8489 - prc: 0.2635 - val_loss: 0.0220 - val_tp: 142.0000 - val_fp: 102.0000 - val_tn: 206171.0000 - val_fn: 1053.0000 - val_accuracy: 0.9944 - val_precision: 0.5820 - val_recall: 0.1188 - val_auc: 0.8575 - val_prc: 0.3398\n",
      "Epoch 3/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0229 - tp: 807.0000 - fp: 575.0000 - tn: 824506.0000 - fn: 3984.0000 - accuracy: 0.9945 - precision: 0.5839 - recall: 0.1684 - auc: 0.8609 - prc: 0.3451 - val_loss: 0.0203 - val_tp: 265.0000 - val_fp: 163.0000 - val_tn: 206110.0000 - val_fn: 930.0000 - val_accuracy: 0.9947 - val_precision: 0.6192 - val_recall: 0.2218 - val_auc: 0.8624 - val_prc: 0.3997\n",
      "Epoch 4/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0213 - tp: 1126.0000 - fp: 637.0000 - tn: 824444.0000 - fn: 3665.0000 - accuracy: 0.9948 - precision: 0.6387 - recall: 0.2350 - auc: 0.8690 - prc: 0.4119 - val_loss: 0.0190 - val_tp: 313.0000 - val_fp: 150.0000 - val_tn: 206123.0000 - val_fn: 882.0000 - val_accuracy: 0.9950 - val_precision: 0.6760 - val_recall: 0.2619 - val_auc: 0.8674 - val_prc: 0.4660\n",
      "Epoch 5/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0197 - tp: 1576.0000 - fp: 660.0000 - tn: 824421.0000 - fn: 3215.0000 - accuracy: 0.9953 - precision: 0.7048 - recall: 0.3290 - auc: 0.8749 - prc: 0.4801 - val_loss: 0.0178 - val_tp: 459.0000 - val_fp: 175.0000 - val_tn: 206098.0000 - val_fn: 736.0000 - val_accuracy: 0.9956 - val_precision: 0.7240 - val_recall: 0.3841 - val_auc: 0.8694 - val_prc: 0.5400\n",
      "Epoch 6/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0185 - tp: 2003.0000 - fp: 672.0000 - tn: 824409.0000 - fn: 2788.0000 - accuracy: 0.9958 - precision: 0.7488 - recall: 0.4181 - auc: 0.8792 - prc: 0.5530 - val_loss: 0.0168 - val_tp: 495.0000 - val_fp: 147.0000 - val_tn: 206126.0000 - val_fn: 700.0000 - val_accuracy: 0.9959 - val_precision: 0.7710 - val_recall: 0.4142 - val_auc: 0.8695 - val_prc: 0.5892\n",
      "Epoch 7/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0175 - tp: 2246.0000 - fp: 683.0000 - tn: 824398.0000 - fn: 2545.0000 - accuracy: 0.9961 - precision: 0.7668 - recall: 0.4688 - auc: 0.8824 - prc: 0.5937 - val_loss: 0.0160 - val_tp: 547.0000 - val_fp: 155.0000 - val_tn: 206118.0000 - val_fn: 648.0000 - val_accuracy: 0.9961 - val_precision: 0.7792 - val_recall: 0.4577 - val_auc: 0.8706 - val_prc: 0.6181\n",
      "Epoch 8/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0170 - tp: 2400.0000 - fp: 696.0000 - tn: 824385.0000 - fn: 2391.0000 - accuracy: 0.9963 - precision: 0.7752 - recall: 0.5009 - auc: 0.8836 - prc: 0.6126 - val_loss: 0.0157 - val_tp: 593.0000 - val_fp: 171.0000 - val_tn: 206102.0000 - val_fn: 602.0000 - val_accuracy: 0.9963 - val_precision: 0.7762 - val_recall: 0.4962 - val_auc: 0.8716 - val_prc: 0.6252\n",
      "Epoch 9/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0163 - tp: 2489.0000 - fp: 706.0000 - tn: 824375.0000 - fn: 2302.0000 - accuracy: 0.9964 - precision: 0.7790 - recall: 0.5195 - auc: 0.8878 - prc: 0.6268 - val_loss: 0.0155 - val_tp: 532.0000 - val_fp: 134.0000 - val_tn: 206139.0000 - val_fn: 663.0000 - val_accuracy: 0.9962 - val_precision: 0.7988 - val_recall: 0.4452 - val_auc: 0.8724 - val_prc: 0.6230\n",
      "Epoch 10/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0160 - tp: 2540.0000 - fp: 707.0000 - tn: 824374.0000 - fn: 2251.0000 - accuracy: 0.9964 - precision: 0.7823 - recall: 0.5302 - auc: 0.8910 - prc: 0.6329 - val_loss: 0.0151 - val_tp: 592.0000 - val_fp: 173.0000 - val_tn: 206100.0000 - val_fn: 603.0000 - val_accuracy: 0.9963 - val_precision: 0.7739 - val_recall: 0.4954 - val_auc: 0.8779 - val_prc: 0.6340\n",
      "Epoch 11/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0156 - tp: 2544.0000 - fp: 692.0000 - tn: 824389.0000 - fn: 2247.0000 - accuracy: 0.9965 - precision: 0.7862 - recall: 0.5310 - auc: 0.8956 - prc: 0.6390 - val_loss: 0.0146 - val_tp: 625.0000 - val_fp: 200.0000 - val_tn: 206073.0000 - val_fn: 570.0000 - val_accuracy: 0.9963 - val_precision: 0.7576 - val_recall: 0.5230 - val_auc: 0.8953 - val_prc: 0.6428\n",
      "Epoch 12/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0151 - tp: 2648.0000 - fp: 726.0000 - tn: 824355.0000 - fn: 2143.0000 - accuracy: 0.9965 - precision: 0.7848 - recall: 0.5527 - auc: 0.9050 - prc: 0.6506 - val_loss: 0.0144 - val_tp: 598.0000 - val_fp: 168.0000 - val_tn: 206105.0000 - val_fn: 597.0000 - val_accuracy: 0.9963 - val_precision: 0.7807 - val_recall: 0.5004 - val_auc: 0.9049 - val_prc: 0.6487\n",
      "Epoch 13/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0148 - tp: 2631.0000 - fp: 729.0000 - tn: 824352.0000 - fn: 2160.0000 - accuracy: 0.9965 - precision: 0.7830 - recall: 0.5492 - auc: 0.9126 - prc: 0.6537 - val_loss: 0.0140 - val_tp: 611.0000 - val_fp: 165.0000 - val_tn: 206108.0000 - val_fn: 584.0000 - val_accuracy: 0.9964 - val_precision: 0.7874 - val_recall: 0.5113 - val_auc: 0.9154 - val_prc: 0.6638\n",
      "Epoch 14/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0143 - tp: 2657.0000 - fp: 727.0000 - tn: 824354.0000 - fn: 2134.0000 - accuracy: 0.9966 - precision: 0.7852 - recall: 0.5546 - auc: 0.9203 - prc: 0.6659 - val_loss: 0.0136 - val_tp: 599.0000 - val_fp: 166.0000 - val_tn: 206107.0000 - val_fn: 596.0000 - val_accuracy: 0.9963 - val_precision: 0.7830 - val_recall: 0.5013 - val_auc: 0.9199 - val_prc: 0.6702\n",
      "Epoch 15/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0138 - tp: 2675.0000 - fp: 718.0000 - tn: 824363.0000 - fn: 2116.0000 - accuracy: 0.9966 - precision: 0.7884 - recall: 0.5583 - auc: 0.9270 - prc: 0.6753 - val_loss: 0.0129 - val_tp: 599.0000 - val_fp: 153.0000 - val_tn: 206120.0000 - val_fn: 596.0000 - val_accuracy: 0.9964 - val_precision: 0.7965 - val_recall: 0.5013 - val_auc: 0.9308 - val_prc: 0.6878\n",
      "Epoch 16/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0134 - tp: 2669.0000 - fp: 745.0000 - tn: 824336.0000 - fn: 2122.0000 - accuracy: 0.9965 - precision: 0.7818 - recall: 0.5571 - auc: 0.9291 - prc: 0.6885 - val_loss: 0.0127 - val_tp: 601.0000 - val_fp: 158.0000 - val_tn: 206115.0000 - val_fn: 594.0000 - val_accuracy: 0.9964 - val_precision: 0.7918 - val_recall: 0.5029 - val_auc: 0.9263 - val_prc: 0.6927\n",
      "Epoch 17/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0129 - tp: 2699.0000 - fp: 706.0000 - tn: 824375.0000 - fn: 2092.0000 - accuracy: 0.9966 - precision: 0.7927 - recall: 0.5633 - auc: 0.9321 - prc: 0.7005 - val_loss: 0.0127 - val_tp: 628.0000 - val_fp: 188.0000 - val_tn: 206085.0000 - val_fn: 567.0000 - val_accuracy: 0.9964 - val_precision: 0.7696 - val_recall: 0.5255 - val_auc: 0.9261 - val_prc: 0.6934\n",
      "Epoch 18/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0127 - tp: 2753.0000 - fp: 719.0000 - tn: 824362.0000 - fn: 2038.0000 - accuracy: 0.9967 - precision: 0.7929 - recall: 0.5746 - auc: 0.9296 - prc: 0.7107 - val_loss: 0.0122 - val_tp: 621.0000 - val_fp: 174.0000 - val_tn: 206099.0000 - val_fn: 574.0000 - val_accuracy: 0.9964 - val_precision: 0.7811 - val_recall: 0.5197 - val_auc: 0.9286 - val_prc: 0.7021\n",
      "Epoch 19/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0125 - tp: 2803.0000 - fp: 733.0000 - tn: 824348.0000 - fn: 1988.0000 - accuracy: 0.9967 - precision: 0.7927 - recall: 0.5851 - auc: 0.9314 - prc: 0.7119 - val_loss: 0.0118 - val_tp: 623.0000 - val_fp: 177.0000 - val_tn: 206096.0000 - val_fn: 572.0000 - val_accuracy: 0.9964 - val_precision: 0.7788 - val_recall: 0.5213 - val_auc: 0.9404 - val_prc: 0.7113\n",
      "Epoch 20/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0124 - tp: 2892.0000 - fp: 763.0000 - tn: 824318.0000 - fn: 1899.0000 - accuracy: 0.9968 - precision: 0.7912 - recall: 0.6036 - auc: 0.9306 - prc: 0.7203 - val_loss: 0.0116 - val_tp: 627.0000 - val_fp: 167.0000 - val_tn: 206106.0000 - val_fn: 568.0000 - val_accuracy: 0.9965 - val_precision: 0.7897 - val_recall: 0.5247 - val_auc: 0.9330 - val_prc: 0.7138\n",
      "Epoch 21/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0121 - tp: 2941.0000 - fp: 750.0000 - tn: 824331.0000 - fn: 1850.0000 - accuracy: 0.9969 - precision: 0.7968 - recall: 0.6139 - auc: 0.9332 - prc: 0.7243 - val_loss: 0.0117 - val_tp: 571.0000 - val_fp: 123.0000 - val_tn: 206150.0000 - val_fn: 624.0000 - val_accuracy: 0.9964 - val_precision: 0.8228 - val_recall: 0.4778 - val_auc: 0.9306 - val_prc: 0.7183\n",
      "Epoch 22/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0121 - tp: 2943.0000 - fp: 739.0000 - tn: 824342.0000 - fn: 1848.0000 - accuracy: 0.9969 - precision: 0.7993 - recall: 0.6143 - auc: 0.9344 - prc: 0.7251 - val_loss: 0.0117 - val_tp: 601.0000 - val_fp: 168.0000 - val_tn: 206105.0000 - val_fn: 594.0000 - val_accuracy: 0.9963 - val_precision: 0.7815 - val_recall: 0.5029 - val_auc: 0.9307 - val_prc: 0.7134\n",
      "Epoch 23/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0120 - tp: 2979.0000 - fp: 752.0000 - tn: 824329.0000 - fn: 1812.0000 - accuracy: 0.9969 - precision: 0.7984 - recall: 0.6218 - auc: 0.9343 - prc: 0.7259 - val_loss: 0.0114 - val_tp: 670.0000 - val_fp: 189.0000 - val_tn: 206084.0000 - val_fn: 525.0000 - val_accuracy: 0.9966 - val_precision: 0.7800 - val_recall: 0.5607 - val_auc: 0.9301 - val_prc: 0.7161\n",
      "Epoch 24/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0118 - tp: 3071.0000 - fp: 741.0000 - tn: 824340.0000 - fn: 1720.0000 - accuracy: 0.9970 - precision: 0.8056 - recall: 0.6410 - auc: 0.9349 - prc: 0.7338 - val_loss: 0.0114 - val_tp: 622.0000 - val_fp: 164.0000 - val_tn: 206109.0000 - val_fn: 573.0000 - val_accuracy: 0.9964 - val_precision: 0.7913 - val_recall: 0.5205 - val_auc: 0.9302 - val_prc: 0.7163\n",
      "Epoch 25/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0119 - tp: 3036.0000 - fp: 760.0000 - tn: 824321.0000 - fn: 1755.0000 - accuracy: 0.9970 - precision: 0.7998 - recall: 0.6337 - auc: 0.9335 - prc: 0.7341 - val_loss: 0.0112 - val_tp: 671.0000 - val_fp: 180.0000 - val_tn: 206093.0000 - val_fn: 524.0000 - val_accuracy: 0.9966 - val_precision: 0.7885 - val_recall: 0.5615 - val_auc: 0.9295 - val_prc: 0.7251\n",
      "Epoch 26/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0116 - tp: 3066.0000 - fp: 743.0000 - tn: 824338.0000 - fn: 1725.0000 - accuracy: 0.9970 - precision: 0.8049 - recall: 0.6399 - auc: 0.9369 - prc: 0.7386 - val_loss: 0.0111 - val_tp: 684.0000 - val_fp: 192.0000 - val_tn: 206081.0000 - val_fn: 511.0000 - val_accuracy: 0.9966 - val_precision: 0.7808 - val_recall: 0.5724 - val_auc: 0.9366 - val_prc: 0.7228\n",
      "Epoch 27/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0115 - tp: 3068.0000 - fp: 753.0000 - tn: 824328.0000 - fn: 1723.0000 - accuracy: 0.9970 - precision: 0.8029 - recall: 0.6404 - auc: 0.9375 - prc: 0.7400 - val_loss: 0.0110 - val_tp: 731.0000 - val_fp: 216.0000 - val_tn: 206057.0000 - val_fn: 464.0000 - val_accuracy: 0.9967 - val_precision: 0.7719 - val_recall: 0.6117 - val_auc: 0.9359 - val_prc: 0.7249\n",
      "Epoch 28/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0114 - tp: 3109.0000 - fp: 765.0000 - tn: 824316.0000 - fn: 1682.0000 - accuracy: 0.9971 - precision: 0.8025 - recall: 0.6489 - auc: 0.9369 - prc: 0.7422 - val_loss: 0.0108 - val_tp: 696.0000 - val_fp: 185.0000 - val_tn: 206088.0000 - val_fn: 499.0000 - val_accuracy: 0.9967 - val_precision: 0.7900 - val_recall: 0.5824 - val_auc: 0.9406 - val_prc: 0.7352\n",
      "Epoch 29/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0115 - tp: 3092.0000 - fp: 788.0000 - tn: 824293.0000 - fn: 1699.0000 - accuracy: 0.9970 - precision: 0.7969 - recall: 0.6454 - auc: 0.9379 - prc: 0.7387 - val_loss: 0.0108 - val_tp: 696.0000 - val_fp: 179.0000 - val_tn: 206094.0000 - val_fn: 499.0000 - val_accuracy: 0.9967 - val_precision: 0.7954 - val_recall: 0.5824 - val_auc: 0.9341 - val_prc: 0.7348\n",
      "Epoch 30/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0113 - tp: 3124.0000 - fp: 763.0000 - tn: 824318.0000 - fn: 1667.0000 - accuracy: 0.9971 - precision: 0.8037 - recall: 0.6521 - auc: 0.9396 - prc: 0.7444 - val_loss: 0.0106 - val_tp: 701.0000 - val_fp: 175.0000 - val_tn: 206098.0000 - val_fn: 494.0000 - val_accuracy: 0.9968 - val_precision: 0.8002 - val_recall: 0.5866 - val_auc: 0.9453 - val_prc: 0.7426\n",
      "Epoch 31/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0113 - tp: 3120.0000 - fp: 765.0000 - tn: 824316.0000 - fn: 1671.0000 - accuracy: 0.9971 - precision: 0.8031 - recall: 0.6512 - auc: 0.9398 - prc: 0.7441 - val_loss: 0.0110 - val_tp: 727.0000 - val_fp: 202.0000 - val_tn: 206071.0000 - val_fn: 468.0000 - val_accuracy: 0.9968 - val_precision: 0.7826 - val_recall: 0.6084 - val_auc: 0.9310 - val_prc: 0.7269\n",
      "Epoch 32/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0110 - tp: 3158.0000 - fp: 800.0000 - tn: 824281.0000 - fn: 1633.0000 - accuracy: 0.9971 - precision: 0.7979 - recall: 0.6592 - auc: 0.9430 - prc: 0.7504 - val_loss: 0.0106 - val_tp: 689.0000 - val_fp: 159.0000 - val_tn: 206114.0000 - val_fn: 506.0000 - val_accuracy: 0.9968 - val_precision: 0.8125 - val_recall: 0.5766 - val_auc: 0.9402 - val_prc: 0.7455\n",
      "Epoch 33/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0110 - tp: 3122.0000 - fp: 761.0000 - tn: 824320.0000 - fn: 1669.0000 - accuracy: 0.9971 - precision: 0.8040 - recall: 0.6516 - auc: 0.9432 - prc: 0.7498 - val_loss: 0.0108 - val_tp: 672.0000 - val_fp: 164.0000 - val_tn: 206109.0000 - val_fn: 523.0000 - val_accuracy: 0.9967 - val_precision: 0.8038 - val_recall: 0.5623 - val_auc: 0.9380 - val_prc: 0.7359\n",
      "Epoch 34/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0109 - tp: 3115.0000 - fp: 749.0000 - tn: 824332.0000 - fn: 1676.0000 - accuracy: 0.9971 - precision: 0.8062 - recall: 0.6502 - auc: 0.9482 - prc: 0.7492 - val_loss: 0.0103 - val_tp: 720.0000 - val_fp: 170.0000 - val_tn: 206103.0000 - val_fn: 475.0000 - val_accuracy: 0.9969 - val_precision: 0.8090 - val_recall: 0.6025 - val_auc: 0.9528 - val_prc: 0.7557\n",
      "Epoch 35/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0108 - tp: 3146.0000 - fp: 770.0000 - tn: 824311.0000 - fn: 1645.0000 - accuracy: 0.9971 - precision: 0.8034 - recall: 0.6566 - auc: 0.9472 - prc: 0.7513 - val_loss: 0.0106 - val_tp: 690.0000 - val_fp: 162.0000 - val_tn: 206111.0000 - val_fn: 505.0000 - val_accuracy: 0.9968 - val_precision: 0.8099 - val_recall: 0.5774 - val_auc: 0.9393 - val_prc: 0.7475\n",
      "Epoch 36/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0109 - tp: 3120.0000 - fp: 789.0000 - tn: 824292.0000 - fn: 1671.0000 - accuracy: 0.9970 - precision: 0.7982 - recall: 0.6512 - auc: 0.9464 - prc: 0.7480 - val_loss: 0.0106 - val_tp: 687.0000 - val_fp: 146.0000 - val_tn: 206127.0000 - val_fn: 508.0000 - val_accuracy: 0.9968 - val_precision: 0.8247 - val_recall: 0.5749 - val_auc: 0.9438 - val_prc: 0.7480\n",
      "Epoch 37/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0107 - tp: 3118.0000 - fp: 754.0000 - tn: 824327.0000 - fn: 1673.0000 - accuracy: 0.9971 - precision: 0.8053 - recall: 0.6508 - auc: 0.9487 - prc: 0.7539 - val_loss: 0.0105 - val_tp: 678.0000 - val_fp: 151.0000 - val_tn: 206122.0000 - val_fn: 517.0000 - val_accuracy: 0.9968 - val_precision: 0.8179 - val_recall: 0.5674 - val_auc: 0.9541 - val_prc: 0.7520\n",
      "Epoch 38/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0107 - tp: 3163.0000 - fp: 779.0000 - tn: 824302.0000 - fn: 1628.0000 - accuracy: 0.9971 - precision: 0.8024 - recall: 0.6602 - auc: 0.9508 - prc: 0.7528 - val_loss: 0.0103 - val_tp: 730.0000 - val_fp: 195.0000 - val_tn: 206078.0000 - val_fn: 465.0000 - val_accuracy: 0.9968 - val_precision: 0.7892 - val_recall: 0.6109 - val_auc: 0.9520 - val_prc: 0.7528\n",
      "Epoch 39/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0106 - tp: 3177.0000 - fp: 791.0000 - tn: 824290.0000 - fn: 1614.0000 - accuracy: 0.9971 - precision: 0.8007 - recall: 0.6631 - auc: 0.9503 - prc: 0.7568 - val_loss: 0.0102 - val_tp: 700.0000 - val_fp: 165.0000 - val_tn: 206108.0000 - val_fn: 495.0000 - val_accuracy: 0.9968 - val_precision: 0.8092 - val_recall: 0.5858 - val_auc: 0.9592 - val_prc: 0.7575\n",
      "Epoch 40/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0105 - tp: 3159.0000 - fp: 760.0000 - tn: 824321.0000 - fn: 1632.0000 - accuracy: 0.9971 - precision: 0.8061 - recall: 0.6594 - auc: 0.9546 - prc: 0.7571 - val_loss: 0.0108 - val_tp: 706.0000 - val_fp: 180.0000 - val_tn: 206093.0000 - val_fn: 489.0000 - val_accuracy: 0.9968 - val_precision: 0.7968 - val_recall: 0.5908 - val_auc: 0.9396 - val_prc: 0.7424\n",
      "Epoch 41/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0106 - tp: 3128.0000 - fp: 796.0000 - tn: 824285.0000 - fn: 1663.0000 - accuracy: 0.9970 - precision: 0.7971 - recall: 0.6529 - auc: 0.9517 - prc: 0.7543 - val_loss: 0.0105 - val_tp: 712.0000 - val_fp: 183.0000 - val_tn: 206090.0000 - val_fn: 483.0000 - val_accuracy: 0.9968 - val_precision: 0.7955 - val_recall: 0.5958 - val_auc: 0.9448 - val_prc: 0.7482\n",
      "Epoch 42/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0105 - tp: 3149.0000 - fp: 771.0000 - tn: 824310.0000 - fn: 1642.0000 - accuracy: 0.9971 - precision: 0.8033 - recall: 0.6573 - auc: 0.9543 - prc: 0.7581 - val_loss: 0.0104 - val_tp: 693.0000 - val_fp: 166.0000 - val_tn: 206107.0000 - val_fn: 502.0000 - val_accuracy: 0.9968 - val_precision: 0.8068 - val_recall: 0.5799 - val_auc: 0.9545 - val_prc: 0.7545\n",
      "Epoch 43/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0103 - tp: 3194.0000 - fp: 775.0000 - tn: 824306.0000 - fn: 1597.0000 - accuracy: 0.9971 - precision: 0.8047 - recall: 0.6667 - auc: 0.9542 - prc: 0.7650 - val_loss: 0.0101 - val_tp: 741.0000 - val_fp: 195.0000 - val_tn: 206078.0000 - val_fn: 454.0000 - val_accuracy: 0.9969 - val_precision: 0.7917 - val_recall: 0.6201 - val_auc: 0.9592 - val_prc: 0.7626\n",
      "Epoch 44/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0103 - tp: 3144.0000 - fp: 754.0000 - tn: 824327.0000 - fn: 1647.0000 - accuracy: 0.9971 - precision: 0.8066 - recall: 0.6562 - auc: 0.9548 - prc: 0.7644 - val_loss: 0.0101 - val_tp: 718.0000 - val_fp: 187.0000 - val_tn: 206086.0000 - val_fn: 477.0000 - val_accuracy: 0.9968 - val_precision: 0.7934 - val_recall: 0.6008 - val_auc: 0.9671 - val_prc: 0.7604\n",
      "Epoch 45/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0102 - tp: 3142.0000 - fp: 785.0000 - tn: 824296.0000 - fn: 1649.0000 - accuracy: 0.9971 - precision: 0.8001 - recall: 0.6558 - auc: 0.9602 - prc: 0.7625 - val_loss: 0.0104 - val_tp: 701.0000 - val_fp: 174.0000 - val_tn: 206099.0000 - val_fn: 494.0000 - val_accuracy: 0.9968 - val_precision: 0.8011 - val_recall: 0.5866 - val_auc: 0.9491 - val_prc: 0.7520\n",
      "Epoch 46/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0103 - tp: 3152.0000 - fp: 781.0000 - tn: 824300.0000 - fn: 1639.0000 - accuracy: 0.9971 - precision: 0.8014 - recall: 0.6579 - auc: 0.9570 - prc: 0.7635 - val_loss: 0.0100 - val_tp: 730.0000 - val_fp: 192.0000 - val_tn: 206081.0000 - val_fn: 465.0000 - val_accuracy: 0.9968 - val_precision: 0.7918 - val_recall: 0.6109 - val_auc: 0.9558 - val_prc: 0.7612\n",
      "Epoch 47/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0102 - tp: 3120.0000 - fp: 770.0000 - tn: 824311.0000 - fn: 1671.0000 - accuracy: 0.9971 - precision: 0.8021 - recall: 0.6512 - auc: 0.9586 - prc: 0.7652 - val_loss: 0.0101 - val_tp: 719.0000 - val_fp: 189.0000 - val_tn: 206084.0000 - val_fn: 476.0000 - val_accuracy: 0.9968 - val_precision: 0.7919 - val_recall: 0.6017 - val_auc: 0.9644 - val_prc: 0.7600\n",
      "Epoch 48/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0100 - tp: 3155.0000 - fp: 764.0000 - tn: 824317.0000 - fn: 1636.0000 - accuracy: 0.9971 - precision: 0.8051 - recall: 0.6585 - auc: 0.9611 - prc: 0.7695 - val_loss: 0.0101 - val_tp: 730.0000 - val_fp: 187.0000 - val_tn: 206086.0000 - val_fn: 465.0000 - val_accuracy: 0.9969 - val_precision: 0.7961 - val_recall: 0.6109 - val_auc: 0.9550 - val_prc: 0.7598\n",
      "Epoch 49/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0101 - tp: 3175.0000 - fp: 776.0000 - tn: 824305.0000 - fn: 1616.0000 - accuracy: 0.9971 - precision: 0.8036 - recall: 0.6627 - auc: 0.9603 - prc: 0.7660 - val_loss: 0.0099 - val_tp: 745.0000 - val_fp: 190.0000 - val_tn: 206083.0000 - val_fn: 450.0000 - val_accuracy: 0.9969 - val_precision: 0.7968 - val_recall: 0.6234 - val_auc: 0.9642 - val_prc: 0.7683\n",
      "Epoch 50/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0100 - tp: 3189.0000 - fp: 782.0000 - tn: 824299.0000 - fn: 1602.0000 - accuracy: 0.9971 - precision: 0.8031 - recall: 0.6656 - auc: 0.9594 - prc: 0.7700 - val_loss: 0.0098 - val_tp: 780.0000 - val_fp: 237.0000 - val_tn: 206036.0000 - val_fn: 415.0000 - val_accuracy: 0.9969 - val_precision: 0.7670 - val_recall: 0.6527 - val_auc: 0.9672 - val_prc: 0.7659\n",
      "Epoch 51/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0100 - tp: 3170.0000 - fp: 766.0000 - tn: 824315.0000 - fn: 1621.0000 - accuracy: 0.9971 - precision: 0.8054 - recall: 0.6617 - auc: 0.9608 - prc: 0.7704 - val_loss: 0.0101 - val_tp: 728.0000 - val_fp: 196.0000 - val_tn: 206077.0000 - val_fn: 467.0000 - val_accuracy: 0.9968 - val_precision: 0.7879 - val_recall: 0.6092 - val_auc: 0.9599 - val_prc: 0.7571\n",
      "Epoch 52/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0099 - tp: 3207.0000 - fp: 796.0000 - tn: 824285.0000 - fn: 1584.0000 - accuracy: 0.9971 - precision: 0.8011 - recall: 0.6694 - auc: 0.9607 - prc: 0.7725 - val_loss: 0.0102 - val_tp: 695.0000 - val_fp: 164.0000 - val_tn: 206109.0000 - val_fn: 500.0000 - val_accuracy: 0.9968 - val_precision: 0.8091 - val_recall: 0.5816 - val_auc: 0.9601 - val_prc: 0.7600\n",
      "Epoch 53/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0098 - tp: 3192.0000 - fp: 749.0000 - tn: 824332.0000 - fn: 1599.0000 - accuracy: 0.9972 - precision: 0.8099 - recall: 0.6662 - auc: 0.9625 - prc: 0.7735 - val_loss: 0.0100 - val_tp: 743.0000 - val_fp: 185.0000 - val_tn: 206088.0000 - val_fn: 452.0000 - val_accuracy: 0.9969 - val_precision: 0.8006 - val_recall: 0.6218 - val_auc: 0.9767 - val_prc: 0.7657\n",
      "Epoch 54/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0098 - tp: 3181.0000 - fp: 761.0000 - tn: 824320.0000 - fn: 1610.0000 - accuracy: 0.9971 - precision: 0.8070 - recall: 0.6640 - auc: 0.9630 - prc: 0.7737 - val_loss: 0.0098 - val_tp: 746.0000 - val_fp: 198.0000 - val_tn: 206075.0000 - val_fn: 449.0000 - val_accuracy: 0.9969 - val_precision: 0.7903 - val_recall: 0.6243 - val_auc: 0.9645 - val_prc: 0.7684\n",
      "Epoch 55/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0098 - tp: 3175.0000 - fp: 758.0000 - tn: 824323.0000 - fn: 1616.0000 - accuracy: 0.9971 - precision: 0.8073 - recall: 0.6627 - auc: 0.9616 - prc: 0.7730 - val_loss: 0.0099 - val_tp: 730.0000 - val_fp: 192.0000 - val_tn: 206081.0000 - val_fn: 465.0000 - val_accuracy: 0.9968 - val_precision: 0.7918 - val_recall: 0.6109 - val_auc: 0.9643 - val_prc: 0.7621\n",
      "Epoch 56/100\n",
      "406/406 [==============================] - 1s 3ms/step - loss: 0.0097 - tp: 3196.0000 - fp: 780.0000 - tn: 824301.0000 - fn: 1595.0000 - accuracy: 0.9971 - precision: 0.8038 - recall: 0.6671 - auc: 0.9625 - prc: 0.7745 - val_loss: 0.0100 - val_tp: 728.0000 - val_fp: 190.0000 - val_tn: 206083.0000 - val_fn: 467.0000 - val_accuracy: 0.9968 - val_precision: 0.7930 - val_recall: 0.6092 - val_auc: 0.9683 - val_prc: 0.7595\n",
      "Epoch 57/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0098 - tp: 3167.0000 - fp: 745.0000 - tn: 824336.0000 - fn: 1624.0000 - accuracy: 0.9971 - precision: 0.8096 - recall: 0.6610 - auc: 0.9647 - prc: 0.7726 - val_loss: 0.0099 - val_tp: 755.0000 - val_fp: 201.0000 - val_tn: 206072.0000 - val_fn: 440.0000 - val_accuracy: 0.9969 - val_precision: 0.7897 - val_recall: 0.6318 - val_auc: 0.9620 - val_prc: 0.7643\n",
      "Epoch 58/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0097 - tp: 3206.0000 - fp: 776.0000 - tn: 824305.0000 - fn: 1585.0000 - accuracy: 0.9972 - precision: 0.8051 - recall: 0.6692 - auc: 0.9635 - prc: 0.7756 - val_loss: 0.0099 - val_tp: 749.0000 - val_fp: 195.0000 - val_tn: 206078.0000 - val_fn: 446.0000 - val_accuracy: 0.9969 - val_precision: 0.7934 - val_recall: 0.6268 - val_auc: 0.9671 - val_prc: 0.7658\n",
      "Epoch 59/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0097 - tp: 3195.0000 - fp: 748.0000 - tn: 824333.0000 - fn: 1596.0000 - accuracy: 0.9972 - precision: 0.8103 - recall: 0.6669 - auc: 0.9629 - prc: 0.7768 - val_loss: 0.0099 - val_tp: 733.0000 - val_fp: 188.0000 - val_tn: 206085.0000 - val_fn: 462.0000 - val_accuracy: 0.9969 - val_precision: 0.7959 - val_recall: 0.6134 - val_auc: 0.9665 - val_prc: 0.7662\n",
      "Epoch 60/100\n",
      "406/406 [==============================] - 1s 4ms/step - loss: 0.0098 - tp: 3207.0000 - fp: 786.0000 - tn: 824295.0000 - fn: 1584.0000 - accuracy: 0.9971 - precision: 0.8032 - recall: 0.6694 - auc: 0.9646 - prc: 0.7753 - val_loss: 0.0098 - val_tp: 724.0000 - val_fp: 183.0000 - val_tn: 206090.0000 - val_fn: 471.0000 - val_accuracy: 0.9968 - val_precision: 0.7982 - val_recall: 0.6059 - val_auc: 0.9700 - val_prc: 0.7670\n",
      "Epoch 61/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0096 - tp: 3206.0000 - fp: 744.0000 - tn: 824337.0000 - fn: 1585.0000 - accuracy: 0.9972 - precision: 0.8116 - recall: 0.6692 - auc: 0.9633 - prc: 0.7773 - val_loss: 0.0098 - val_tp: 754.0000 - val_fp: 205.0000 - val_tn: 206068.0000 - val_fn: 441.0000 - val_accuracy: 0.9969 - val_precision: 0.7862 - val_recall: 0.6310 - val_auc: 0.9673 - val_prc: 0.7648\n",
      "Epoch 62/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0097 - tp: 3214.0000 - fp: 778.0000 - tn: 824303.0000 - fn: 1577.0000 - accuracy: 0.9972 - precision: 0.8051 - recall: 0.6708 - auc: 0.9645 - prc: 0.7767 - val_loss: 0.0099 - val_tp: 738.0000 - val_fp: 197.0000 - val_tn: 206076.0000 - val_fn: 457.0000 - val_accuracy: 0.9968 - val_precision: 0.7893 - val_recall: 0.6176 - val_auc: 0.9788 - val_prc: 0.7620\n",
      "Epoch 63/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0096 - tp: 3223.0000 - fp: 769.0000 - tn: 824312.0000 - fn: 1568.0000 - accuracy: 0.9972 - precision: 0.8074 - recall: 0.6727 - auc: 0.9663 - prc: 0.7796 - val_loss: 0.0098 - val_tp: 716.0000 - val_fp: 166.0000 - val_tn: 206107.0000 - val_fn: 479.0000 - val_accuracy: 0.9969 - val_precision: 0.8118 - val_recall: 0.5992 - val_auc: 0.9671 - val_prc: 0.7694\n",
      "Epoch 64/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0096 - tp: 3193.0000 - fp: 744.0000 - tn: 824337.0000 - fn: 1598.0000 - accuracy: 0.9972 - precision: 0.8110 - recall: 0.6665 - auc: 0.9670 - prc: 0.7768 - val_loss: 0.0097 - val_tp: 742.0000 - val_fp: 192.0000 - val_tn: 206081.0000 - val_fn: 453.0000 - val_accuracy: 0.9969 - val_precision: 0.7944 - val_recall: 0.6209 - val_auc: 0.9685 - val_prc: 0.7698\n",
      "Epoch 65/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0095 - tp: 3228.0000 - fp: 737.0000 - tn: 824344.0000 - fn: 1563.0000 - accuracy: 0.9972 - precision: 0.8141 - recall: 0.6738 - auc: 0.9646 - prc: 0.7821 - val_loss: 0.0098 - val_tp: 747.0000 - val_fp: 196.0000 - val_tn: 206077.0000 - val_fn: 448.0000 - val_accuracy: 0.9969 - val_precision: 0.7922 - val_recall: 0.6251 - val_auc: 0.9634 - val_prc: 0.7674\n",
      "Epoch 66/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0096 - tp: 3206.0000 - fp: 761.0000 - tn: 824320.0000 - fn: 1585.0000 - accuracy: 0.9972 - precision: 0.8082 - recall: 0.6692 - auc: 0.9663 - prc: 0.7781 - val_loss: 0.0100 - val_tp: 724.0000 - val_fp: 197.0000 - val_tn: 206076.0000 - val_fn: 471.0000 - val_accuracy: 0.9968 - val_precision: 0.7861 - val_recall: 0.6059 - val_auc: 0.9697 - val_prc: 0.7611\n",
      "Epoch 67/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0096 - tp: 3209.0000 - fp: 761.0000 - tn: 824320.0000 - fn: 1582.0000 - accuracy: 0.9972 - precision: 0.8083 - recall: 0.6698 - auc: 0.9687 - prc: 0.7785 - val_loss: 0.0099 - val_tp: 717.0000 - val_fp: 165.0000 - val_tn: 206108.0000 - val_fn: 478.0000 - val_accuracy: 0.9969 - val_precision: 0.8129 - val_recall: 0.6000 - val_auc: 0.9656 - val_prc: 0.7679\n",
      "Epoch 68/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0096 - tp: 3211.0000 - fp: 761.0000 - tn: 824320.0000 - fn: 1580.0000 - accuracy: 0.9972 - precision: 0.8084 - recall: 0.6702 - auc: 0.9641 - prc: 0.7788 - val_loss: 0.0100 - val_tp: 707.0000 - val_fp: 172.0000 - val_tn: 206101.0000 - val_fn: 488.0000 - val_accuracy: 0.9968 - val_precision: 0.8043 - val_recall: 0.5916 - val_auc: 0.9672 - val_prc: 0.7626\n",
      "Epoch 69/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0095 - tp: 3219.0000 - fp: 731.0000 - tn: 824350.0000 - fn: 1572.0000 - accuracy: 0.9972 - precision: 0.8149 - recall: 0.6719 - auc: 0.9664 - prc: 0.7827 - val_loss: 0.0099 - val_tp: 731.0000 - val_fp: 187.0000 - val_tn: 206086.0000 - val_fn: 464.0000 - val_accuracy: 0.9969 - val_precision: 0.7963 - val_recall: 0.6117 - val_auc: 0.9667 - val_prc: 0.7653\n",
      "Epoch 70/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0096 - tp: 3214.0000 - fp: 768.0000 - tn: 824313.0000 - fn: 1577.0000 - accuracy: 0.9972 - precision: 0.8071 - recall: 0.6708 - auc: 0.9655 - prc: 0.7819 - val_loss: 0.0099 - val_tp: 714.0000 - val_fp: 174.0000 - val_tn: 206099.0000 - val_fn: 481.0000 - val_accuracy: 0.9968 - val_precision: 0.8041 - val_recall: 0.5975 - val_auc: 0.9731 - val_prc: 0.7654\n",
      "Epoch 71/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0096 - tp: 3203.0000 - fp: 743.0000 - tn: 824338.0000 - fn: 1588.0000 - accuracy: 0.9972 - precision: 0.8117 - recall: 0.6685 - auc: 0.9650 - prc: 0.7794 - val_loss: 0.0098 - val_tp: 704.0000 - val_fp: 164.0000 - val_tn: 206109.0000 - val_fn: 491.0000 - val_accuracy: 0.9968 - val_precision: 0.8111 - val_recall: 0.5891 - val_auc: 0.9727 - val_prc: 0.7655\n",
      "Epoch 72/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0096 - tp: 3201.0000 - fp: 748.0000 - tn: 824333.0000 - fn: 1590.0000 - accuracy: 0.9972 - precision: 0.8106 - recall: 0.6681 - auc: 0.9652 - prc: 0.7794 - val_loss: 0.0099 - val_tp: 729.0000 - val_fp: 183.0000 - val_tn: 206090.0000 - val_fn: 466.0000 - val_accuracy: 0.9969 - val_precision: 0.7993 - val_recall: 0.6100 - val_auc: 0.9774 - val_prc: 0.7626\n",
      "Epoch 73/100\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0095 - tp: 3198.0000 - fp: 745.0000 - tn: 824336.0000 - fn: 1593.0000 - accuracy: 0.9972 - precision: 0.8111 - recall: 0.6675 - auc: 0.9687 - prc: 0.7826 - val_loss: 0.0098 - val_tp: 723.0000 - val_fp: 166.0000 - val_tn: 206107.0000 - val_fn: 472.0000 - val_accuracy: 0.9969 - val_precision: 0.8133 - val_recall: 0.6050 - val_auc: 0.9621 - val_prc: 0.7669\n",
      "Epoch 74/100\n",
      "403/406 [============================>.] - ETA: 0s - loss: 0.0095 - tp: 3157.0000 - fp: 740.0000 - tn: 819834.0000 - fn: 1613.0000 - accuracy: 0.9971 - precision: 0.8101 - recall: 0.6618 - auc: 0.9670 - prc: 0.7805Restoring model weights from the end of the best epoch: 64.\n",
      "406/406 [==============================] - 2s 4ms/step - loss: 0.0096 - tp: 3167.0000 - fp: 744.0000 - tn: 824337.0000 - fn: 1624.0000 - accuracy: 0.9971 - precision: 0.8098 - recall: 0.6610 - auc: 0.9667 - prc: 0.7797 - val_loss: 0.0096 - val_tp: 727.0000 - val_fp: 180.0000 - val_tn: 206093.0000 - val_fn: 468.0000 - val_accuracy: 0.9969 - val_precision: 0.8015 - val_recall: 0.6084 - val_auc: 0.9737 - val_prc: 0.7693\n",
      "Epoch 74: early stopping\n"
     ]
    }
   ],
   "source": [
    "#class weights 0:1, 1:10\n",
    "baseline_history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(val_features, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406/406 [==============================] - 0s 923us/step\n",
      "127/127 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)\n",
    "baseline_results = model.evaluate(test_features, test_labels,batch_size=BATCH_SIZE, verbose=0)\n",
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.00956952665001154\n",
      "tp :  999.0\n",
      "fp :  257.0\n",
      "tn :  257558.0\n",
      "fn :  521.0\n",
      "accuracy :  0.9970000386238098\n",
      "precision :  0.7953821420669556\n",
      "recall :  0.6572368144989014\n",
      "auc :  0.9638153314590454\n",
      "prc :  0.7749637365341187\n",
      "Legitimate Transactions Detected (True Negatives):  257558\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  257\n",
      "Fraudulent Transactions Missed (False Negatives):  521\n",
      "Fraudulent Transactions Detected (True Positives):  999\n",
      "Total Fraudulent Transactions:  1520\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "plot_cm(test_labels, test_predictions_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: FraudModel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('FraudModel')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml3950')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
